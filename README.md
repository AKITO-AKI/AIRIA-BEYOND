# AIRIA BEYOND

An AI-powered session management and mood tracking application.

ğŸš€ **Live Demo**: [https://akito-aki.github.io/AIRIA-BEYOND/](https://akito-aki.github.io/AIRIA-BEYOND/)

## Pre-release: Quick Start (é…å¸ƒç”¨)

ãƒ—ãƒ¬ãƒªãƒªãƒ¼ã‚¹ã§ã€Œè¿·ã‚ãšèµ·å‹•ã€ã§ãã‚‹æœ€çŸ­æ‰‹é †ã§ã™ã€‚

1) å…±æœ‰URLã‚’é–‹ã
- https://akito-aki.github.io/AIRIA-BEYOND/

2) ã€Œãƒ­ã‚°ã‚¤ãƒ³ã—ã¦ã¯ã˜ã‚ã‚‹ã€
- ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ã§æ–°è¦ç™»éŒ² â†’ ãƒ­ã‚°ã‚¤ãƒ³

   - **OpenAI**: [https://platform.openai.com/api-keys](https://platform.openai.com/api-keys)
- æ—©ãè©¦ã—ãŸã„å ´åˆã¯ã€Œå‰µä½œã‹ã‚‰ã€ã‚’é¸ã¶ï¼ˆã‚¹ãƒ†ãƒƒãƒ—æ•°ãŒçŸ­ã„ï¼‰
- æœ€å¾Œã«ã€Œå®Œäº†ã€â†’ æ¬¡ç”»é¢ã§ã€Œã¯ã˜ã‚ã‚‹ã€

4) ç”Ÿæˆã‚’ä½“é¨“
- ã€Œ1æ›²ä½œã£ã¦ã¯ã˜ã‚ã‚‹ã€ã§ã€ã‚ªãƒ³ãƒœãƒ¼ãƒ‡ã‚£ãƒ³ã‚°å›ç­”ã‹ã‚‰1æ›²ç”Ÿæˆã—ã¦ãã®ã¾ã¾å†ç”Ÿ
- ç”ŸæˆãŒæ­¢ã¾ã£ãŸ/é€šä¿¡ãŒåˆ‡ã‚ŒãŸå ´åˆã¯ã€Œç”Ÿæˆã‚’å†é–‹ã€ã§å¾©å¸°ã§ãã¾ã™
3. Add your token to `.env`:
```
OPENAI_API_KEY=your_openai_api_key_here
```

### ç›´æ¥ãƒªãƒ³ã‚¯ï¼ˆãƒ—ãƒ¬ãƒ­ã‚°ã‚¤ãƒ³ï¼‰
**Note:**
- Image generation is ComfyUI-only (`IMAGE_PROVIDER=comfyui`).
- Without `OPENAI_API_KEY`, the app uses rule-based (or Ollama if configured).
- Set `DISABLE_LLM_ANALYSIS=true` to force rule-based analysis (for cost control).
- åˆ©ç”¨è¦ç´„: https://akito-aki.github.io/AIRIA-BEYOND/#terms

### ã¤ã¾ãšãã‚„ã™ã„ãƒã‚¤ãƒ³ãƒˆ

- ã€ŒInvalid credentialsã€ã¯ãƒ¡ãƒ¼ãƒ«/ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒé•ã†å ´åˆã«å‡ºã¾ã™ã€‚
- ç›´å‰ã«æ–°è¦ç™»éŒ²ã—ãŸã®ã«ãƒ­ã‚°ã‚¤ãƒ³ã§ããªã„å ´åˆã€ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã®å†èµ·å‹•/å†ãƒ‡ãƒ—ãƒ­ã‚¤ã§èªè¨¼ã‚¹ãƒˆã‚¢ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ï¼ˆãƒ—ãƒ¬ãƒªãƒªãƒ¼ã‚¹ã¯ `api/data/auth-store.json` ã®ãƒ­ãƒ¼ã‚«ãƒ«ã‚¹ãƒˆã‚¢æ–¹å¼ã§ã™ï¼‰ã€‚
- ç”Ÿæˆã¯ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯çŠ¶æ³ã§ 1ã€œ2åˆ†ç¨‹åº¦ã‹ã‹ã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ï¼ˆå¤±æ•—ã—ã¦ã‚‚é€²è¡Œã™ã‚‹ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯è¨­è¨ˆã§ã™ï¼‰ã€‚

è£œè¶³:
- ãƒ—ãƒ¬ãƒªãƒªãƒ¼ã‚¹ã¯ãƒ¡ãƒ¼ãƒ«/ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã®ã¿ï¼ˆOAuthç„¡åŠ¹ï¼‰ã§ã™ã€‚
### å°åˆ·ç”¨ãƒãƒ©ã‚·ï¼ˆQR/URLï¼‰

- å°åˆ·ãƒšãƒ¼ã‚¸: [docs/flyer.html](docs/flyer.html)
- URLå·®ã—æ›¿ãˆ: `docs/flyer.html?url=https://example.com/`ï¼ˆä¸Šéƒ¨ãƒ„ãƒ¼ãƒ«ãƒãƒ¼ã‹ã‚‰ã‚‚å¤‰æ›´å¯èƒ½ï¼‰

## Architecture

AIRIA BEYOND uses a split architecture for cost-effective deployment:

- **Frontend**: GitHub Pages (static hosting) - `https://akito-aki.github.io/AIRIA-BEYOND/`
- **Backend API**: Render (Node.js/Express) - `https://airia-beyond.onrender.com`

Custom domain migration guide:
- See [docs/CUSTOM_DOMAIN_MIGRATION.md](./docs/CUSTOM_DOMAIN_MIGRATION.md)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  https://akito-aki.github.ioâ”‚
â”‚  /AIRIA-BEYOND/             â”‚
â”‚  https://airia-beyond.      â”‚
â”‚  onrender.com               â”‚
â”‚  /api/*                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**See [docs/RENDER_DEPLOYMENT.md](./docs/RENDER_DEPLOYMENT.md) for deployment instructions.**

## ãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—

æ¬¡ã«å„ªå…ˆã—ã¦èª¿æ•´ï¼å®Ÿè£…ã—ã¦ã„ãé …ç›®ï¼ˆUXã€ä¿¡é ¼æ€§ã€ãƒ—ãƒ­ãƒã‚¤ãƒ€å“è³ªã€æœ¬ç•ªé‹ç”¨ã®ç¡¬ã•ï¼‰ã‚’ [docs/ROADMAP.md](./docs/ROADMAP.md) ã«ã¾ã¨ã‚ã¦ã„ã¾ã™ã€‚

## ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆï¼ˆçµ±åˆï¼‰

ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¯æ•£ã‚‰ã°ã‚Šã‚’æ¸›ã‚‰ã™ãŸã‚ã€å…¥å£ã‚’ [docs/INDEX.md](./docs/INDEX.md) ã«çµ±åˆã—ã¾ã—ãŸã€‚

- å…¨ä½“åƒãƒ»æ€æƒ³ãƒ»ãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—: [docs/PRODUCT.md](./docs/PRODUCT.md)
- é–‹ç™ºãƒ»ãƒ†ã‚¹ãƒˆï¼ˆã‚¹ãƒ¢ãƒ¼ã‚¯/strictå«ã‚€ï¼‰: [docs/DEV_GUIDE.md](./docs/DEV_GUIDE.md)
- é‹ç”¨ãƒ»ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ»ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£: [docs/OPS_GUIDE.md](./docs/OPS_GUIDE.md)
- å¼•ãç¶™ããƒ­ã‚°ï¼ˆã“ã®ãƒãƒ£ãƒƒãƒˆã®ä½œæ¥­å±¥æ­´ï¼‰: [docs/CHAT_HANDOVER_LOG.md](./docs/CHAT_HANDOVER_LOG.md)

## Repository Structure

```
AIRIA-BEYOND/
â”œâ”€â”€ apps/
â”‚   â””â”€â”€ web/              # Main web application (Vite + React + TypeScript)
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ routes/           # Express API routes
â”‚   â”œâ”€â”€ controllers/      # Express API controllers
â”‚   â”œâ”€â”€ lib/              # Utility libraries (rate limiting, etc.)
â”‚   â””â”€â”€ *.js              # Supporting modules (job stores, LLM services, etc.)
â”œâ”€â”€ packages/
â”‚   â””â”€â”€ core/             # Shared core packages
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/        # CI/CD workflows
â”œâ”€â”€ server.js             # Express API server entry point
â”œâ”€â”€ render.yaml           # Render deployment configuration
â””â”€â”€ package.json          # Monorepo root configuration
```

## Prerequisites

- **Node.js**: >= 18.0.0
- **npm**: >= 9.0.0

Check your versions:
```bash
node --version
npm --version
```

## Installation

From the repository root, run:

```bash
npm install
```

This will install all dependencies for the monorepo workspaces.

## Configuration

### Environment Variables

This project generates images via **ComfyUI** (SDXL workflow). LLM features (analysis / optional Art Director prompt layer) can use OpenAI or Ollama.

1. Copy the example environment file:
```bash
cp .env.example .env
```

2. Configure ComfyUI (required for image generation):
```
IMAGE_PROVIDER=comfyui
COMFYUI_BASE_URL=http://127.0.0.1:8188
# Optional but recommended for determinism
COMFYUI_CHECKPOINT=sdxl_base_1.0.safetensors
```

3. Configure OpenAI (optional; enables LLM analysis and the Art Director prompt layer):
- Get your API token: https://platform.openai.com/api-keys
```
OPENAI_API_KEY=your_openai_api_key_here
```

Notes:
- Without `OPENAI_API_KEY`, the app uses rule-based analysis (or Ollama if configured).
- Set `DISABLE_LLM_ANALYSIS=true` to force rule-based analysis (for cost control).

### Email/Password Login (Pre-release)

Pre-release uses **email/password only**. OAuth (Google/Apple) is disabled by default.

If you deploy **Frontend: Netlify** + **Backend: Render**, make sure both sides are set and redeployed:

- Netlify (build-time env):
  - `VITE_API_BASE_URL=https://airia-beyond.onrender.com`
  - `VITE_PUBLIC_BASE_PATH=/`
- Render (runtime env):
  - `APP_PUBLIC_URL=https://<your-netlify-site>.netlify.app`
  - `APP_ALLOWED_ORIGINS=https://<your-netlify-site>.netlify.app`
  - `AUTH_ALLOW_PASSWORD=true`

Tip: The login screen includes a â€œæ¥ç¶š/èªè¨¼ãƒã‚§ãƒƒã‚¯ï¼ˆè¨ºæ–­ï¼‰â€ panel. If it shows `passwordEnabled=false`, password login is blocked by backend env.

Backend env vars:
```
# Default: true
AUTH_ALLOW_PASSWORD=true

# Default: false
AUTH_ALLOW_OAUTH=false

# Persistence options
#
# Option A (Recommended / Free): Neon Postgres
# - Create a Neon database and set DATABASE_URL on the backend.
# - When DATABASE_URL is set, the auth store uses Postgres instead of a JSON file.
DATABASE_URL=postgresql://...

# Option B: Persist the auth store to a disk mount (Render disk may be paid)
# Example: /var/data/auth-store.json (see render.yaml)
AUTH_STORE_PATH=/var/data/auth-store.json
```

Frontend (Vite) env vars:
```
# Default: false (hide OAuth UI)
VITE_ENABLE_OAUTH=false

# API endpoint
VITE_API_BASE_URL=https://airia-beyond.onrender.com

# Base path (GitHub Pages: /AIRIA-BEYOND/, custom domain: /)
VITE_PUBLIC_BASE_PATH=/AIRIA-BEYOND/
```

### Email Notifications (Optional)

Email notifications are **disabled by default** and are designed to be **no-op** unless explicitly enabled.

Backend env vars:
```
EMAIL_NOTIFICATIONS_ENABLED=false
EMAIL_FROM=...
APP_PUBLIC_URL=https://akito-aki.github.io/AIRIA-BEYOND/
```

Choose one provider:

- **Resend**
```
RESEND_API_KEY=...
```

- **SMTP**
```
SMTP_HOST=...
SMTP_PORT=587
SMTP_USER=...
SMTP_PASS=...
SMTP_SECURE=false
```

Current triggers (best-effort):
- Social: like / comment / follow
- Music: job succeeded (only if the frontend sends the Bearer token)

### Local-first (Ollama + ComfyUI)

If you want to avoid paid services (OpenAI), run everything locally:

1) Start Ollama and pull a model
```bash
ollama serve
ollama pull qwen2.5:7b-instruct
```

2) Start ComfyUI (default: http://127.0.0.1:8188)
- Make sure you have a checkpoint installed (e.g. SDXL checkpoint under `models/checkpoints`).

3) Set env vars
```
LLM_PROVIDER=ollama
IMAGE_PROVIDER=comfyui

OLLAMA_BASE_URL=http://127.0.0.1:11434
OLLAMA_MODEL=qwen2.5:7b-instruct

COMFYUI_BASE_URL=http://127.0.0.1:8188
COMFYUI_CHECKPOINT=sdxl_base_1.0.safetensors

# Debug logs (writes to .debug/ai)
DEBUG_AI=1
```

Provider behavior:
- `/api/chat` and `/api/event/refine` use Ollama when `LLM_PROVIDER=ollama`.
- `/api/image/generate` uses ComfyUI when `IMAGE_PROVIDER=comfyui`.

### Smoke test (debug)

These commands help you quickly verify ComfyUI and the Image API wiring.

- Direct ComfyUI test (requires ComfyUI running at `COMFYUI_BASE_URL`):
```bash
npm run smoke:comfyui
```

- Image API test via `/api/image/generate` + `/api/job/:id` (requires API server running):
```bash
npm run dev:api
npm run smoke:image:comfyui
```

Tips:
- Save lots of logs: set `DEBUG_AI=1` (writes JSON logs to `.debug/ai`).
- The API smoke test writes the resulting image file into `.debug/smoke/`.

### Cost and Rate Limits

- **Rate Limiting**: 5 requests per minute per IP address
- **Concurrency**: Maximum 3 concurrent image generations per IP
- **Costs**: Image generation cost depends on your ComfyUI host (GPU / cloud).
- **Generation Time**: 30-120 seconds per image (varies by GPU/workflow)

## Development

### Running Locally (Frontend + API)

To run both the frontend and API together:

```bash
npm run dev
```

This starts:
- Frontend (Vite) at `http://localhost:5173/AIRIA-BEYOND/`
- Backend API (Express) at `http://localhost:3000/api/*`

**Alternative: Run separately**

Frontend only:
```bash
npm run dev:web
```

Backend API only:
```bash
npm run dev:api  # or npm run server:dev
```

### Build for Production

```bash
npm run build
```

This creates an optimized production build in `apps/web/dist/`

### Preview Production Build

```bash
npm run preview
```

This serves the production build locally for testing.

## MVP Flow

### Phase A: Room Navigation
- Multi-room layout with 5 distinct rooms:
  - **Onboarding**: Welcome and deep-life questions
  - **Main**: Session management and PNG generation
  - **Gallery**: Content placeholder
  - **Album**: Content placeholder
  - **Music**: Content placeholder
- Smooth horizontal swipe navigation between rooms
- Touch and mouse drag support for intuitive room switching
- Click navigation buttons at the top for direct room access
- Minimal white + transparency styling
- Internal routing without external dependencies

### Phase B: Onboarding Deep-Life Questions (NEW!)
- 4-step questionnaire capturing foundational emotional data:
  1. **Recent Emotional Moment**: When, what emotion, and why it happened
  2. **Daily Emotional Pattern**: Time of day and associated emotions
  3. **Emotional Triggers**: Key factors that influence emotions and their importance
  4. **Emotional Goals**: Desired emotional state and timeline for achievement
- Mix of dropdowns and minimal free-text inputs for easy answering
- Data stored in localStorage for persistence
- Progress indicator showing current step
- Blend-mode text effects for elegant minimal design
- Exportable profile data as JSON
- Designed to capture life data that an LLM cannot infer later

### Phase 1: Session Management & JSON Export
- Japanese UI with session start/stop
- 4-choice mood selection (ç©ã‚„ã‹, å¬‰ã—ã„, ä¸å®‰, ç–²ã‚Œ)
- 30s-3m duration
- Intermediate representation JSON download

### Phase 2: PNG Generation
- Generate abstract generative art from session data
- Deterministic image generation (same session data â†’ same PNG)
- Mood-based color palettes:
  - ç©ã‚„ã‹ (Calm): Cool blues
  - å¬‰ã—ã„ (Happy): Warm yellows/oranges
  - ä¸å®‰ (Anxious): Grays
  - ç–²ã‚Œ (Tired): Earth tones
- Duration influences visual complexity
- On-screen preview and PNG download

### Phase P1: Robust Generation Flow (NEW! ğŸ‰)
- **Enhanced Job State Management**:
  - Retry tracking with `retryCount` and `maxRetries` (default: 3)
  - Error tracking with standardized error codes (TIMEOUT, NETWORK_ERROR, API_ERROR, etc.)
  - Complete lifecycle logging (created â†’ running â†’ succeeded/failed)
  - Full input parameter storage for retry capability

- **Timeout Handling**:
  - 120-second timeout for API calls to prevent hung requests
  - Automatic job failure on timeout with TIMEOUT error code
  - Comprehensive timeout event logging

- **Server-Side Automatic Retry**:
  - Automatic retry on transient errors (network issues, 5xx server errors)
  - Exponential backoff between retries (2s â†’ 4s â†’ 8s, max 30s)
  - Stops after 3 retries and marks as permanently failed
  - All retry attempts logged with context

- **Client-Side Manual Retry**:
  - Retry button appears on failed jobs in the UI
  - Creates new job with same input parameters
  - Clear user feedback during retry process

- **Fallback Mechanism**:
  - Option to fall back to local Canvas generation on external failure
  - Clear Japanese prompt: "å¤–éƒ¨ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ­ãƒ¼ã‚«ãƒ«ç”Ÿæˆã«åˆ‡ã‚Šæ›¿ãˆã¾ã™ã‹ï¼Ÿ"
  - Seamless transition to deterministic local generation

- **Enhanced UI Status Display**:
  - Clear display for all job states (queued/running/succeeded/failed)
  - Animated progress indicator with spinner
  - Detailed error information with error codes and messages
  - Retry count display (e.g., "ãƒªãƒˆãƒ©ã‚¤å›æ•°: 1/3")
  - Job ID display for tracking

- **Error Logging & Monitoring**:
  - All job lifecycle events logged with timestamps
  - Context includes provider, model, input summary, error details
  - Standardized error codes for consistent monitoring

- **Job Cleanup**:
  - Admin endpoints for job management (`GET/DELETE /api/admin/jobs`)
  - Auto-cleanup of old jobs after 1 hour

**User Experience**: Never leaves users stuck! Always provides clear feedback, automatic recovery from transient errors, manual retry options, and fallback to local generation when needed.

### Phase P2: LLM-based Analysis (NEW! ğŸ‰)
- **Intelligent Session Analysis**:
  - Uses OpenAI GPT-4o-mini to generate intermediate representation (IR) from session data
  - Analyzes mood, duration, and optional free text to produce emotional metrics
  - Returns valence (-1 to +1), arousal (0 to 1), focus (0 to 1), and artistic motif tags

- **Intermediate Representation (IR)**:
  - **Valence**: Emotional pleasantness (-1=unpleasant, +1=pleasant)
  - **Arousal**: Energy level (0=calm, 1=excited)
  - **Focus**: Attention/concentration level (0 to 1)
  - **Motif Tags**: 3-5 classical/artistic vocabulary terms (e.g., é™å¯‚, æ°´é¢, å…‰, å½±)
  - **Confidence**: Analysis certainty (0 to 1)
  - **Classical Profile**: Optional hints for music generation (tempo, dynamics, harmony)

- **LLM Prompt Design**:
  - Japanese-language prompt with classical music and fine art context
  - Rich vocabulary: light/shadow (å…‰/å½±), nature (æ°´é¢/éœ§/æ£®), emotion (å­¤ç‹¬/è˜å³/é™å¯‚)
  - Strict JSON output with examples for guidance
  - Emphasizes classical music and painting aesthetics

- **JSON Validation**:
  - Zod schema validation ensures type safety and range constraints
  - Validation failures logged with raw LLM response
  - One retry attempt with stricter prompt
  - Falls back to rule-based on persistent validation errors

- **Rule-based Fallback**:
  - Deterministic generation when LLM unavailable or fails
  - Mood-based mappings (ç©ã‚„ã‹â†’valence:0.6, å¬‰ã—ã„â†’valence:0.8, etc.)
  - Duration influences focus (longer sessions = higher focus, capped at 0.9)
  - Predefined motif tags per mood category
  - Always returns confidence: 0.5 for rule-based

- **Privacy-First Design**:
  - No raw audio or video sent to LLM
  - Only text-based session metadata (mood, duration, optional freeText)
  - onboardingData optional and user-controlled
  - Timestamp for context

- **Analysis API (`/api/analyze`)**:
  - POST endpoint returns job ID immediately (202 Accepted)
  - Async processing with status polling
  - Integrates with P1 job system (retry, timeout, error handling)
  - Rate limited (5 req/min) and concurrency limited (3 concurrent)

- **Client Integration**:
  - Analysis runs automatically before image generation
  - Beautiful gradient UI card displays IR results to user
  - Shows valence, arousal, focus, motif tags, and confidence
  - Analysis status indicator with provider (openai/rule-based)
  - IR data flows seamlessly into SDXL image generation

- **Cost Control**:
  - `DISABLE_LLM_ANALYSIS=true` env var forces rule-based mode
  - Token usage logged for monitoring
  - GPT-4o-mini used for cost efficiency (~$0.15 per 1M tokens)

**User Experience**: Get AI-powered emotional insights before image generation! The system analyzes your session and displays artistic interpretation with classical music vocabulary, then generates images that reflect your analyzed emotional state.

### Phase P3: Full Image Generation Pipeline (NEW! ğŸ‰)
- **Enhanced Prompt Generation from IR**:
  - Valence (-1 to +1) â†’ atmosphere keywords (dark/bright, melancholic/uplifting)
  - Arousal (0 to 1) â†’ energy keywords (calm/intense, peaceful/dynamic)
  - Focus (0 to 1) â†’ composition clarity (diffuse/sharp, ethereal/crisp)
  - Automatic translation of Japanese motif tags to English for SDXL
  - Rich classical aesthetic vocabulary integration

- **Auto-Style Preset Selection**:
  - Intelligent style choice based on valence/arousal values
  - Low arousal + positive valence â†’ watercolor (calm, soft)
  - High arousal â†’ romantic landscape (dramatic, intense)
  - Customizable manual selection available

- **Updated Style Presets**:
  - **æ²¹çµµ** (Oil Painting): Thick brushstrokes, rich texture, classical
  - **æ°´å½©ç”»** (Watercolor): Soft edges, translucent layers, delicate
  - **å°è±¡æ´¾** (Impressionism): Light-focused, natural scenery, atmospheric
  - **æŠ½è±¡ãƒŸãƒ‹ãƒãƒ«** (Abstract Minimal): Monochrome gradient, geometric calm
  - **ãƒ­ãƒãƒ³æ´¾é¢¨æ™¯** (Romantic Landscape): Dramatic sky, sublime nature

- **Enhanced Album System**:
  - Full metadata storage: IR data, generation parameters, style, seed, provider
  - Beautiful organized metadata display in Album view
  - Provider badges in Gallery (AI / ãƒ­ãƒ¼ã‚«ãƒ«)
  - Regenerate function: same parameters, new seed for variations

- **Progress Flow Visualization**:
  - 3-step visual indicator: è§£æä¸­ â†’ ç”»åƒç”Ÿæˆä¸­ â†’ å®Œäº†
  - Animated states with pulse effects
  - Clear feedback through entire pipeline

- **Complete Pipeline Integration**:
  - Session â†’ Analysis (P2) â†’ Prompt (P3) â†’ Image (P0/P1) â†’ Album â†’ Gallery
  - Seamless metadata flow through all stages
  - Fallback to local generation on failures

**User Experience**: Complete journey from session to gallery! Create sessions, watch AI analyze your emotions, generate beautiful classical-style art, save to albums with full metadata, and explore your emotional collection in the 3D gallery bookshelf. Regenerate variations with a single click!

### Phase P0: High-quality Image Generation (ComfyUI)
- High-quality AI image generation using ComfyUI (SDXL workflow)
- Style presets for classic aesthetics (see P3 for updated presets)
- Automatic prompt generation from session IR data (mood, duration, tags)
- Asynchronous job processing with real-time status updates
- Fallback to placeholder/local generation on failures
- Rate limiting and concurrency guards for stability
- 1024x1024px high-quality output

## Usage

### Completing the Onboarding (Onboarding Room)

1. **Navigate to the Onboarding room** using the navigation buttons

2. **Answer 4 deep-life questions:**
   - **Step 1**: Describe a recent emotional moment (when, what emotion, why)
   - **Step 2**: Identify your daily emotional patterns (time and emotion)
   - **Step 3**: Specify your main emotional triggers (what and why)
   - **Step 4**: Set emotional goals (what you want to achieve and when)

3. **Progress through the questions:**
   - Each step requires all fields to be filled before proceeding
   - Use the "æ¬¡ã¸ â†’" button to advance to the next step
   - Use the "â† æˆ»ã‚‹" button to go back and edit previous answers
   - Click "âœ“ å®Œäº†" on the final step to complete

4. **After completion:**
   - Your answers are automatically saved in your browser
   - Download your profile as JSON using "ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"
   - Edit your answers anytime with "å›ç­”ã‚’ç·¨é›†"

The onboarding data is stored locally and can be used to personalize your session experience.

### Navigating Between Rooms

1. **Start the development server:**
   ```bash
   npm run dev
   ```
   Navigate to `http://localhost:5173/AIRIA-BEYOND/`

2. **Navigate between rooms:**
   - Click on room buttons at the top (Onboarding, Main, Gallery, Album, Music)
   - Swipe left/right or drag with mouse to move between rooms
   - The active room is highlighted in the navigation bar

### Running a Session and Generating Images (Main Room)

1. **Navigate to the Main room** using the navigation buttons

2. **Create a session:**
   - Select a mood (ç©ã‚„ã‹, å¬‰ã—ã„, ä¸å®‰, or ç–²ã‚Œ)
   - Select a duration (30s, 60s, 120s, or 180s)
   - Click "Start" to begin the session
   - Click "Stop" when finished

3. **Download session data:**
   - Click "Download JSON" to save the intermediate representation

4. **Generate and download PNG:**
   - Click "PNGç”Ÿæˆ" to generate an abstract image based on your session
   - View the preview on screen
   - Click "Download PNG" to save the generated image

5. **Generate with AI (ComfyUI) - P3 Enhanced:**
   - Select a style preset (æ²¹çµµ, æ°´å½©ç”», å°è±¡æ´¾, etc.) or let auto-select based on your mood
   - Click "é«˜å“è³ªç”Ÿæˆ(ComfyUI)" to generate a high-quality AI image
   - **Watch the progress flow:**
     - Step 1: "è§£æä¸­..." - AI analyzes your session (2-5 seconds)
     - See your emotional analysis (valence, arousal, focus, motif tags)
     - Step 2: "ç”»åƒç”Ÿæˆä¸­..." - ComfyUI generates image (30-120 seconds)
     - Step 3: "å®Œäº†" - Generation complete!
   - View retry count if automatic retries occur
   - Wait 30-120 seconds for generation to complete
   - If it fails:
     - Click "ğŸ”„ å†è©¦è¡Œ" to manually retry
     - Or click "ğŸ¨ ãƒ­ãƒ¼ã‚«ãƒ«ç”Ÿæˆã«åˆ‡ã‚Šæ›¿ãˆ" to use local generation
   - Click "ğŸ“š ã‚¢ãƒ«ãƒãƒ ã«ä¿å­˜" to save to album with full metadata
   - Note: LLM analysis is optional (OpenAI/Ollama); image generation runs on your ComfyUI host

6. **View your albums in Gallery:**
   - Navigate to Gallery room
   - See your saved images as 3D book spines
   - Notice "AI" or "ãƒ­ãƒ¼ã‚«ãƒ«" badges showing generation method
   - Hover over books to see metadata tooltip
   - Click a book to view full details in Album room

7. **Album details and regeneration:**
   - In Album room, view organized metadata:
     - Basic info (mood, duration, creation date)
     - Emotional analysis (valence, arousal, focus, motifs, confidence)
     - Generation parameters (style, seed, provider)
   - For AI-generated images, click "ğŸ”„ å†ç”Ÿæˆ (æ–°ã—ã„ã‚·ãƒ¼ãƒ‰)" to create a variation
   - New variation saved as separate album with new seed

The generated images reflect your emotional state through intelligent prompt generation combining mood, analysis results, and classical aesthetic vocabulary.

## Project Status

**Phase P3 (Prototype)**: âœ… Full image generation pipeline complete - Enhanced prompt generation from IR, auto-style selection, complete album system with metadata, gallery integration, regeneration, and visual progress flow.

**Phase P2 (Prototype)**: âœ… LLM-based analysis complete - OpenAI integration, intermediate representation generation, rule-based fallback, JSON validation, and beautiful UI display of emotional insights.

**Phase P1 (Prototype)**: âœ… Robust generation flow complete - Timeout handling, automatic retry with exponential backoff, manual retry UI, fallback mechanism, enhanced error display, and comprehensive logging.

**Phase P0 (Prototype)**: âœ… High-quality image generation integration complete - ComfyUI with style presets, job tracking, rate limiting, and fallback support.

**Phase B**: Onboarding deep-life questions complete - 4-step questionnaire capturing emotional patterns, triggers, and goals with localStorage persistence.

**Phase A**: Room navigation complete - multi-room layout with smooth swipe/touch navigation.

**Phase 1-2**: Session management and PNG generation complete - abstract generative art from session IR.

**Phase 3**: GitHub Pages deployment configured - automatic deployment on push to main branch.

## Testing

### Running Tests

é–‹ç™ºãƒ»ãƒ†ã‚¹ãƒˆãƒ»ã‚¹ãƒ¢ãƒ¼ã‚¯ï¼ˆstrict-provider ã‚’å«ã‚€ï¼‰ã¯ [docs/DEV_GUIDE.md](./docs/DEV_GUIDE.md) ã«çµ±åˆã—ã¾ã—ãŸã€‚

æ—§ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆï¼ˆP1ã€œP5 ã®å®Ÿè£…ã‚µãƒãƒªç­‰ï¼‰ã¯ [docs/archive/](./docs/archive/) ã«é€€é¿ã—ã¦ã„ã¾ã™ã€‚

### P3 Test Scenarios

1. **End-to-End Flow:**
   - Create session â†’ Watch analysis â†’ See IR results â†’ Image generation â†’ Save to album â†’ View in gallery â†’ Open album details
   
2. **Auto-Style Selection:**
   - Create sessions with different moods
   - Observe different style auto-selection based on emotional analysis
   
3. **Progress Flow:**
   - Watch 3-step progress indicator during generation
   - Verify animated states and completion markers

4. **Album Metadata:**
   - Save album and verify all metadata is stored
   - Check IR values, style preset, seed, provider
   
5. **Gallery Features:**
   - Verify provider badges appear on book spines
   - Hover to see metadata tooltips
   
6. **Regeneration:**
   - Open AI-generated album
   - Click regenerate button
   - Verify new album created with same style but different seed

### Quick Test
- Admin endpoints

### Quick Test

1. Start the development server:
```bash
npm run dev
```

2. Create a session in Main room

3. Try external generation (with or without API token to test fallback)

4. Verify status updates and retry/fallback options

## Security

ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã®è¦ç‚¹ï¼ˆå„ªå…ˆåº¦é †ï¼‰ã¯ [docs/OPS_GUIDE.md](./docs/OPS_GUIDE.md) ã«çµ±åˆã—ã¾ã—ãŸï¼ˆæ—§ç‰ˆã¯ [docs/SECURITY_SUMMARY.md](./docs/SECURITY_SUMMARY.md) ã‹ã‚‰å‚ç…§ã§ãã¾ã™ï¼‰ã€‚

**Key Security Features:**
- Rate limiting (5 requests/min per IP)
- Concurrency limiting (3 concurrent jobs per IP)
- 120-second timeout protection
- Input validation
- No SQL injection risk (in-memory storage)
- Environment variable protection for API tokens

**Pre-existing Dependency Vulnerabilities:**
- 3 vulnerabilities in @vercel/node dependencies
- Recommend upgrading in a separate maintenance task

## Documentation

ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®å…¥å£ã¯ [docs/INDEX.md](./docs/INDEX.md) ã§ã™ã€‚

- å…¨ä½“åƒãƒ»æ€æƒ³ãƒ»ãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—: [docs/PRODUCT.md](./docs/PRODUCT.md)
- é–‹ç™ºãƒ»ãƒ†ã‚¹ãƒˆ: [docs/DEV_GUIDE.md](./docs/DEV_GUIDE.md)
- é‹ç”¨ãƒ»ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ»ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£: [docs/OPS_GUIDE.md](./docs/OPS_GUIDE.md)
- å¼•ãç¶™ããƒ­ã‚°: [docs/CHAT_HANDOVER_LOG.md](./docs/CHAT_HANDOVER_LOG.md)

æ—§ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¯ [docs/archive/legacy/](./docs/archive/legacy/) ã«é€€é¿ã—ã¦ã„ã¾ã™ã€‚

## Deployment

- Xserverï¼ˆå…±æœ‰ã‚µãƒ¼ãƒï¼‰ã¸ç§»è¡Œã™ã‚‹å ´åˆ: [docs/XSERVER_DEPLOYMENT.md](docs/XSERVER_DEPLOYMENT.md)
- Xserver VPS ã§ API ã‚’é‹ç”¨ã™ã‚‹å ´åˆ: [docs/XSERVER_VPS_DEPLOYMENT.md](docs/XSERVER_VPS_DEPLOYMENT.md)

### GitHub Pages (Frontend Only)

The static frontend is automatically deployed to GitHub Pages when changes are pushed to the main branch. The deployment workflow:
1. Builds the application using `npm run build`
2. Uploads the build artifacts from `apps/web/dist/`
3. Deploys to GitHub Pages at https://akito-aki.github.io/AIRIA-BEYOND/

**Note:** GitHub Pages only hosts the static frontend. External image generation requires the API to be deployed separately.

### Vercel (Full Stack - Recommended)

â€»ã“ã®ç¯€ã¯æ—§æ§‹æˆã®åæ®‹ã§ã™ã€‚ç¾çŠ¶ã¯ã€Œãƒ•ãƒ­ãƒ³ãƒˆé™çš„ + API å¸¸æ™‚ç¨¼åƒï¼ˆRender / VPSï¼‰ã€ã‚’æ¨å¥¨ã—ã¦ã„ã¾ã™ï¼ˆè©³ç´°: [docs/OPS_GUIDE.md](./docs/OPS_GUIDE.md)ï¼‰ã€‚

For the complete experience with external image generation:

1. Install Vercel CLI: `npm install -g vercel`
2. Link to Vercel: `vercel link`
3. Add environment variables (ComfyUI-only):
  - `vercel env add IMAGE_PROVIDER` (set to `comfyui`)
  - `vercel env add COMFYUI_BASE_URL` (must be reachable from the deployed backend)
4. Deploy: `vercel --prod`

The `vercel.json` configuration automatically handles:
- Frontend build from `apps/web/dist`
- Serverless API functions from `/api`
- API routing at `/api/*`

### Manual Deployment Testing

To test the production build locally before deployment:

```bash
npm run build
npm run preview
```

This will build and serve the app at `http://localhost:4173/AIRIA-BEYOND/`

## Contributing

This is a monorepo using npm workspaces. All commands at the root proxy to the appropriate workspace.
